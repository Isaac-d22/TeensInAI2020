{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression | Jasamrit Rahala\n",
    "---\n",
    "\n",
    "Linear regression is a commonly used regression analysis model used by many data scientists and businesses. It is a comparitively simple model allowing for quick and easy usage. As well as this, the intuition behind the model is rather simple making it the 'hello world' for artificial intelligence and machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Real World Applications\n",
    "---\n",
    "\n",
    "Applications of linear regression in the real world include:\n",
    "\n",
    "- predict sales of products based on consumer behaviour\n",
    "- predict the price of houses in the coming years\n",
    "- predict the performance of sports players based on their experience\n",
    "\n",
    "Linear regression is a verstaile used by many different businesses. It is under the family of models known as generalised linear models. Below is an implementation of linear regression using the python package sklearn. In a practical scenario, one is expected to use packages inlcuding sklearn, tensorflow, numpy etc. simply because of their optimisation (threading, GPU) though the fundamental processes and concepts remain the same.\n",
    "\n",
    "\n",
    "### Housing Dataset | Sklearn\n",
    "---\n",
    "\n",
    "In the example below I show how linear regression would be used in the real world, with libraries like sklearn. However in this notebook we will focus on how the model works behind the scenes. Feel free to use this as reference when making your own linear regression models. Below I import the necessary libraries to create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt         # visualisation library\n",
    "%matplotlib inline                     \n",
    "import numpy as np                     # mathematics library (needed for sklearn)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression     # machine learning library (import linear regression model from here)\n",
    "from sklearn import datasets                          # testing and training datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above I have imported the libraries, now lets import the data. I am using data from the sklearn datasets. In particular I will be using the boston house prices dataset. This contains the prices of houses within boston given 13 other variables (which we can use to predict house prices with). Let's get a better understanding of the data below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()               # load data using the dataset from sklearn\n",
    "\n",
    "print(boston.data.shape)                      # shape of the training data\n",
    "print(boston.target.shape)                    # shape of the target data (in our case, house prices)\n",
    "print(boston.feature_names)                   # names of the columns\n",
    "\n",
    "# print(boston.DESCR) - uncomment this to get a full description of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you uncomment the last line above, you will get a full explanation of the data that we are working with. The training data contains useful variables including, crime rates and pupil-teacher ratios in regions. Now we can start to prep the data for training. As you know, we have to split the data into a training set and a testing set. We do this to avoid memorization in the model. A nice way to think about this is the following example:\n",
    "\n",
    "<blockquote>\n",
    "    \n",
    "If I give you a test containing ten difficult questions about calculus, you are likely to get most of them wrong. After I mark the test, I return to you the test with the correct answers. If I were to give you the same test and repeat this process. Over time you would learn the answers to the questions. This seems good however if I were to give you another test on the same topic but with slighlty different questions you are not likely to score as well as you did previously. This is because you memorized the data and didn't learn. \n",
    "\n",
    "Let's say instead of giving you the same test everyday I give you a different test on the same topic. You would still get low marks however over time you would take the time to learn what each question is asking and recognise patterns. It would still a take a while to learn however when you start gettin questions right, you can get them right because you understand the theory. Therefore when I give you any questions on calculus you should be able to answer them correctly.\n",
    "    \n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperating the testing and training data using the 'train_test_split function'\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.2, random_state=0)\n",
    "\n",
    "model = LinearRegression()        # Create a model instance\n",
    "model.fit(X_train, y_train)       # Use the fit method on the model\n",
    "model.score(X_test, y_test)       # Check the model's score\n",
    "\n",
    "# from sklearn import metrics\n",
    "# print(metrics.mean_squared_error(y_test, model.predict(X_test))) -- uncomment for the mse error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we have split up our data using the train_test_split function. The data and target variables are specified as arguments in the function and test_size is set to 0.2. Meaning that 20% of the data will be split as testing data. The testing inputs are stored as X_test and the training inputs are stored as X_train. Whereas the testing outputs are stored as y_test and the training, stored as y_train. \n",
    "\n",
    "After we split the data we can create the LinearRegression() object and saved it under the model variable. We then fit the model using model.fit() method with the training inputs and outputs. Then we can test the model using the model.score() method. The numbers that are returned from the model.score() can seem rather arbitrary alone and it unclear as to what they represent. \n",
    "\n",
    "The model.score() gives us (by default) the R-Squared metric for analysing how well our model fits our data. \n",
    "R Squared is used a lot in investing to indicate how much variance is unexplained (not predicted by our line). \n",
    "\n",
    "$${R^{2} = 1 - \\frac{\\text{Unexplained variation}}{\\text{Total variation}}}$$\n",
    "\n",
    "We won't go over this, but you can read more about R Squared [here](https://www.investopedia.com/terms/r/r-squared.asp#:~:text=To%20calculate%20the%20total%20variance,you%20have%20the%20R%2Dsquared \"R squared\").\n",
    "\n",
    "A single R Squared value by itself isn't very useful without context to other R Squared values. In our example we can see how well our model fits the data by eye. However when we deal with higher dimensions and more complex models, plotting a learning curve of R^2 values can be very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'COEFFICIENTS: {model.coef_}')            # Get the coefficients, beta\n",
    "print(f'INTERCEPT   : {model.intercept_}')       # Get the intercept, c\n",
    "\n",
    "# plot prediction and actual data\n",
    "\n",
    "y_pred = model.predict(X_test) \n",
    "plt.plot(y_test, y_pred, '.')\n",
    "\n",
    "# plotting the line our linear regression predicted based on testing data\n",
    "\n",
    "x = np.linspace(0, 50, 100)\n",
    "y = x\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can use the model to predict that testing data again. This time we can plot the predictions against the real data. As you can see the correlation between the predicted line (orange) is linked to the real data points (blue). We can also print out the co-efficients used by the model as well as the intercept. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our own Linear Regression model\n",
    "---\n",
    "\n",
    "Now that we have seen the linear regression model in action it is time to build our own and really understand what is going on behind the scenes. For example what does model.fit() and model.predict() really do? By understanding the concepts and coding along, you can more easily debug your own code as well as modify existing code. Plus there wont always be a sklearn library to help you with some languages. By having the ability to write your own model you can also implement much more easily with your own projects.\n",
    "\n",
    "\n",
    "### The Data\n",
    "---\n",
    "\n",
    "For this project we will be using a dataset that I have created. The dataset contains student test scores (%) and the minutes a student has spent revising for a test. This dataset should cover the basic principles of linear regression. To import the dataset I am using a library called requests - this allows me to pull data of websites. Since I have hosted my data as a .txt on github this is useful for retrieving the data. __Do not worry if you dont understand the below, it is merely retrieving and formatting the data.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "dataset = requests.get('https://raw.githubusercontent.com/JRahala/tempStorage/master/StudentData.txt').text.replace('\\r','')\n",
    "\n",
    "dataset = dataset.split('\\n')[1:-1]\n",
    "\n",
    "scores = []\n",
    "minutes = []\n",
    "\n",
    "for datapoint in dataset:\n",
    "    \n",
    "    (score, minute) = datapoint.split(',')\n",
    "    \n",
    "    scores.append(float(score))\n",
    "    minutes.append(float(minute))\n",
    "    \n",
    "print(scores[:5], minutes[:5])\n",
    "plt.scatter(minutes, scores, s = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above you can see the first five samples of data and a plot of the data. I have made the correlation easy to see for teaching reasons. This way you will be able to tell if your model works. The data above contains no missing values and has been turned into float values so they can be used in calculations. But before we can start to use the data to train a model. We need to split the data into testing and training data. Please complete the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_test_train(inputs, outputs, test = 0.2):\n",
    "    \n",
    "    train_samples = len(dataset)\n",
    "    \n",
    "    # split the data here\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_test_train(minutes, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all the data processing that needs to be done for this dataset. Now lets move onto creating the linear regression class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Linear Regression Class\n",
    "---\n",
    "\n",
    "The linear regression class will first of all need an \\__init\\__() function. This will construct our class. Inside this function we can define how many dimensions our model will work for. Dimensions refers to the number of features in our input data. For example we are going to be predicting scores given minutes. We are only using minutes as our input, this is one feature. Therefore our model will be one-dimensional.\n",
    "\n",
    "We will also need a predict method which will take in an array of inputs and multiply them by the respective weights.\n",
    "\n",
    "Below I have created a skeleton for the linear regression class. Please fill in the remaining code where commented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random  # allows us to randomise the model parameters\n",
    "\n",
    "\n",
    "class LinearRegression:\n",
    "    \n",
    "    def __init__(self, dimensions):\n",
    "        \n",
    "        self.dimensions = dimensions\n",
    "        self.weights = [random.random() for weight in range(self.dimensions + 1)]\n",
    "        \n",
    "        # I have added 1 to the dimensions since we have to account for a constant term (bias)\n",
    "        # In terms of lines this will be the +c part of y = mx + c\n",
    "        \n",
    "        # Our weights array is essentially = [m, c]\n",
    "        \n",
    "    def predict(self, inputs):\n",
    "        \n",
    "        # write code here - the predict method should take an array of inputs and return an output based on that array\n",
    "        output = 0\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After filling in the above we have our basic linear regression model, however it isn't very smart. Let's create a cost function to see how well / badly it performs given our data. Please fill in the code where commented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(self, inputs, outputs):\n",
    "    \n",
    "    # inputs represents the array of minutes in our case\n",
    "    # outputs represents the array of scores in our case\n",
    "    \n",
    "    # use the self.predict method to form a prediction and calculate the sum of squared errors based on the real values\n",
    "    # optionally you can take the mean of this sum\n",
    "    \n",
    "    error = 0\n",
    "    for index in range(len(inputs)):\n",
    "        \n",
    "        error += 0 # write code that uses the adds the squared difference to the total error\n",
    "        \n",
    "    return error\n",
    "    \n",
    "    \n",
    "# add this method to the linear regression class\n",
    "LinearRegression.cost = cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to create a linear regression instance / object. I have created a LinearRegression() object below. I have also added a visualisation function that will help visualise our model's predictions using matplotlib (a graphing libarary) against real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # this will allow us to visualise graphs and charts\n",
    "\n",
    "def plot(self, inputs, outputs):\n",
    "            \n",
    "    # scatter plot our training data\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        plt.scatter(inputs[i], outputs[i], c = 'red')\n",
    "\n",
    "    # we are plotting from y = 0 to y = 100; we can rearrange our equation and solve for x to plot the datapoints; y - c / m = x\n",
    "    \n",
    "    plt.plot([-self.weights[1] / self.weights[0],100-self.weights[1] / self.weights[0]] ,[0, 100], c = 'black')    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# add this method to the linear regression class\n",
    "LinearRegression.plot = plot\n",
    "    \n",
    "myModel = LinearRegression(1) # create the linear regression object\n",
    "myModel.plot(X_train, y_train) # plot the training inputs and outputs\n",
    "\n",
    "print('model fit:', myModel.cost(X_train, y_train)) # print how well our model fits the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have got the plotting to work, then you should see a black line indicating our prediction line and red dots, indicating real datapoints. Before we move on to actually training the model, have a play around with some of the weights for our model and try to understand how adjusting the weights of our model can change how well the model fits the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "---\n",
    "\n",
    "Now that we have a basic model that can predict data, lets fine tune the model so that its predictions are more useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training | Brute force approach\n",
    "\n",
    "The easiest way to compute the best weights for our model is by brute forcing them. We can exhaust the values that the weights for our model could be by testing the cost for each pairing of weights. Below is a loop that I have set up which plots the cost of each set of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "costMap = []\n",
    "\n",
    "for m in range(-100, 100):\n",
    "    \n",
    "    row = []\n",
    "    \n",
    "    for c in range(-100, 100):\n",
    "        \n",
    "        myModel.weights = [m, c]\n",
    "        row.append(-1 * myModel.cost(X_train, y_train))\n",
    "        \n",
    "    costMap.append(row)\n",
    "    \n",
    "plt.imshow(costMap, cmap='hot')\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above the code you should see a heat map of cost values. The Y axis represents different values of M and the X axis represents the C values. There should be a highlighted spot in the plot above. This spot shows the lowest cost. I.e. the best values for m and c for our line. Whilst this is useful and true, the process can be computationally expensive (we are computing 200 x 200 operations). As well as this the results are not very precise. We only get integer accuracy.\n",
    "\n",
    "*You might notice the x -1 infront of the cost output, this is purely for aesthetics when plotting on the map\n",
    "\n",
    "Lets try to solve the problem of finding M and C (the weights of our model) using calculus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training | Calculus\n",
    "---\n",
    "\n",
    "Lets take another look at the problem. We can produce a 3D plot based on the costs given m and c. The plot will look like below. You can have a go at plotting your own curve based on this 3D Plotting documentation https://matplotlib.org/3.1.1/gallery/mplot3d/scatter3d.html, if you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image](https://raw.githubusercontent.com/JRahala/tempStorage/master/Curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically this curve should be convex. For us that means there is one minimum point on the curve. This would mean there exists one minimum point for cost (point B). One configuration of m and c with the lowest cost. This also means that at any point on the curve there exists a gradient that will point towards / away from the minimum. By figuring out the gradient at a given point on the curve (for example point A) we can move towards the minimum point. Remember our point on the curve will be defined by our current weights (m and c). So how can we go about finding the gradient and using this to change our weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training | Calculus Intuition\n",
    "---\n",
    "\n",
    "This article / video should give you the a helping hand with some of the calculus needed for linear regression.\n",
    "https://towardsdatascience.com/linear-regression-using-gradient-descent-97a6c8700931\n",
    "\n",
    "If you do need more help with the calculus do feel free to contact me via discord.\n",
    "Please refer to the video to understand the rules below.\n",
    "\n",
    "### Training | Update Rules\n",
    "---\n",
    "\n",
    "To update the weights for our linear regression line, weights[0] (m) and weights[1] (c), we use the rules below.\n",
    "\n",
    "<br>\n",
    "\n",
    "$$ \\Delta W_{0} -= \\frac{\\partial J}{\\partial W_{0}} $$\n",
    "$$ \\Delta W_{1} -= \\frac{\\partial J}{\\partial W_{1}} $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial W_{0}} = 2x \\cdot \\sum_{i}^{n}(f(x) - y_{i}) $$\n",
    "$$ \\frac{\\partial J}{\\partial W_{1}} = 2 \\cdot \\sum_{i}^{n}(f(x) - y_{i}) $$\n",
    "\n",
    "<br>\n",
    "\n",
    "Have a go at implementing this update rule in your linear regression model. Remember $ f(x) $ represents our model's guess and $ y_{i} $ is the actual datapoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, inputs, outputs):\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        \n",
    "        current_input = inputs[i]\n",
    "        current_output = outputs[i]\n",
    "        \n",
    "        error = # what would this be?\n",
    "        \n",
    "        self.weights[0] -= 2 * inputs[i] * error\n",
    "        self.weights[1] -= 2 * error    \n",
    "        \n",
    "LinearRegression.train = train # add this method to our class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This really concludes the training stage of linear regression. You can experiment by analysing this model. Try looping the train function and measure the cost over time. Perhaps plotting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = LinearRegression(1) # create the linear regression object\n",
    "myModel.train(X_train, y_train) # try and make this function work\n",
    "\n",
    "# try looping over the train function and plotting the model at different stages during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "---\n",
    "\n",
    "Now that we have successfully built our linear regression model, lets try some variations. The first thing we can do is test the model on the training data we seperated at the start. Try doing this in the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all down to you now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As well as this, we can try changing what is known as the learning rate of the training function. The learning rate has been discussed in the video and tells us how much effect each training step should have. Below is a visualisation of the effect of learning rates.\n",
    "\n",
    "![Image](https://raw.githubusercontent.com/JRahala/tempStorage/master/learning_rates.png)\n",
    "\n",
    "Try to redefine the train function with a learning rate and experiment with different learning rates. Analyse the cost over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_train(self, inputs, outputs, lr = 0.5): # set the default learning rate to 0.5\n",
    "    \n",
    "    for i in range(len(inputs)):\n",
    "        \n",
    "        current_input = inputs[i]\n",
    "        current_output = outputs[i]\n",
    "        \n",
    "        error = # what would this be?\n",
    "        # how can you add the learning_Rate into the equation?\n",
    "        \n",
    "        self.weights[0] -= 2 * inputs[i] * error\n",
    "        self.weights[1] -= 2 * error    \n",
    "        \n",
    "LinearRegression.lr_train = lr_train # add this method to our class\n",
    "myModel = LinearRegression(1)\n",
    "\n",
    "# try and use the lr_train function with a learning rate - see what happens when you change lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many other things you can achieve with linear regression and many other analyitical methods to see your models fit and how we can optimise this method. Using some more calculus, there are more advanced methods to train the model.\n",
    "\n",
    "I have added some links below for further reading and if you have any questions (either because you are stuck or want more, do feel free to contact me on discord (JAM) and check out github JRahala for more projects).\n",
    "\n",
    "- https://365datascience.com/sum-squares/\n",
    "- https://www.youtube.com/watch?v=nk2CQITm_eo\n",
    "- https://www.youtube.com/watch?v=PaFPbb66DxQ\n",
    "- https://www.youtube.com/watch?v=sDv4f4s2SB8\n",
    "\n",
    "Thanks,\n",
    "Jam"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
